{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b7e4612a43e499c903e01605700af50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97ea316964874edda0810f679c9a457c",
              "IPY_MODEL_c00b126e19e64326b8f1b91dfd2c1266",
              "IPY_MODEL_c54d7b1ac44a47ad985e3af578df5fa9"
            ],
            "layout": "IPY_MODEL_74c6a6c732a94553ba1ef32ba66981fe"
          }
        },
        "97ea316964874edda0810f679c9a457c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62cec7bd8d045dc8c9045943bc38f07",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9b5946f45644e2bef623895d0f2009",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "c00b126e19e64326b8f1b91dfd2c1266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83958d5a3a954e0da7f04347900b3904",
            "max": 167747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37adfac928204953998ab02d8c90ddc4",
            "value": 167747
          }
        },
        "c54d7b1ac44a47ad985e3af578df5fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5194bdf323471b97048546627f74cc",
            "placeholder": "​",
            "style": "IPY_MODEL_155c099faaa141758b66995f1092dce3",
            "value": " 168k/168k [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "74c6a6c732a94553ba1ef32ba66981fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62cec7bd8d045dc8c9045943bc38f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9b5946f45644e2bef623895d0f2009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83958d5a3a954e0da7f04347900b3904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37adfac928204953998ab02d8c90ddc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa5194bdf323471b97048546627f74cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155c099faaa141758b66995f1092dce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55cc1ecd24134f08bb7511e9298fae0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e758bc27bd4f389f67f3461b94985c",
              "IPY_MODEL_03310292fb2b40c8b2fd3b53591202da",
              "IPY_MODEL_330037291a2245faa69f90f67c52f534"
            ],
            "layout": "IPY_MODEL_04df8c29e56a4894991cec7360cabdc7"
          }
        },
        "b7e758bc27bd4f389f67f3461b94985c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50762926df0f4e259724c80ec5af6ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f3d6effdd8453399cd33d1faed1e5b",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "03310292fb2b40c8b2fd3b53591202da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148559f8e57242ca8aa6bdac0354f1ce",
            "max": 4974351586,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d59fb6a333244acca86df182a5cb02b4",
            "value": 4974351586
          }
        },
        "330037291a2245faa69f90f67c52f534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05b6289ebe146eaa86acf3bbdc8df84",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ecb5e835244ecca03f4821e773b33e",
            "value": " 4.97G/4.97G [00:24&lt;00:00, 50.9MB/s]"
          }
        },
        "04df8c29e56a4894991cec7360cabdc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50762926df0f4e259724c80ec5af6ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f3d6effdd8453399cd33d1faed1e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148559f8e57242ca8aa6bdac0354f1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59fb6a333244acca86df182a5cb02b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f05b6289ebe146eaa86acf3bbdc8df84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ecb5e835244ecca03f4821e773b33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf52ec753ffe49d9bb43234988662bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83903f3f783842bb81df068217e0e71f",
              "IPY_MODEL_1073f86287e94c6b807e2f4355646422",
              "IPY_MODEL_5317ad3fdfb246a1bb0dd08eac8bad3e"
            ],
            "layout": "IPY_MODEL_5fe137895099446d9c336cb73d72be8a"
          }
        },
        "83903f3f783842bb81df068217e0e71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c7eaea87434c7696a9d5d528a1d17c",
            "placeholder": "​",
            "style": "IPY_MODEL_cb1402d028554e22ae0f75e37412dca2",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "1073f86287e94c6b807e2f4355646422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338ba8971e3f4fdba128948ee260fb5a",
            "max": 4589082716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1f5d9ce022140228d17e113c6e75785",
            "value": 4589082716
          }
        },
        "5317ad3fdfb246a1bb0dd08eac8bad3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14cba64ec8584dc49a1ee6a61c164acf",
            "placeholder": "​",
            "style": "IPY_MODEL_6a03ec4fb2eb400f998a498604e988ae",
            "value": " 4.59G/4.59G [00:39&lt;00:00, 308MB/s]"
          }
        },
        "5fe137895099446d9c336cb73d72be8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c7eaea87434c7696a9d5d528a1d17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1402d028554e22ae0f75e37412dca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "338ba8971e3f4fdba128948ee260fb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f5d9ce022140228d17e113c6e75785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14cba64ec8584dc49a1ee6a61c164acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a03ec4fb2eb400f998a498604e988ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be26f25f73b4a818ec5cb1539a04025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe5c549b8647457fbf5df03ac28919df",
              "IPY_MODEL_d3b24e8951dc4fca94958d89abaa14cf",
              "IPY_MODEL_ad00552793764af19224a469a3aa7c61"
            ],
            "layout": "IPY_MODEL_9b5722e538ad4c269a82970dd391a17c"
          }
        },
        "fe5c549b8647457fbf5df03ac28919df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50fde704eb34472b9543ecd5ca1a464",
            "placeholder": "​",
            "style": "IPY_MODEL_db7d8870ceee438e8d516c1ee95b721d",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "d3b24e8951dc4fca94958d89abaa14cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033e975dddc744888dd4c2e0c30a3cb5",
            "max": 1555824768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5239e420f4b648da8dae632d6eb60cf8",
            "value": 1555824768
          }
        },
        "ad00552793764af19224a469a3aa7c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ddb1b13366c4e75b214ecf5c5772ed1",
            "placeholder": "​",
            "style": "IPY_MODEL_9f09248028674aeaad1fd458c22883ec",
            "value": " 1.56G/1.56G [00:07&lt;00:00, 401MB/s]"
          }
        },
        "9b5722e538ad4c269a82970dd391a17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50fde704eb34472b9543ecd5ca1a464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db7d8870ceee438e8d516c1ee95b721d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "033e975dddc744888dd4c2e0c30a3cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5239e420f4b648da8dae632d6eb60cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ddb1b13366c4e75b214ecf5c5772ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f09248028674aeaad1fd458c22883ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc7182d4f81d47baacb7c1d9767ee8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_115efb345de24148930316c7dd14ab87",
              "IPY_MODEL_2cf0afc6b55b4544953eed5a2dbe89c0",
              "IPY_MODEL_37b6560af5094e9a9127b604b53120d7"
            ],
            "layout": "IPY_MODEL_17ec49acb79b481ab2a31d07d022aafa"
          }
        },
        "115efb345de24148930316c7dd14ab87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731755722d05494bb560560ab63685f8",
            "placeholder": "​",
            "style": "IPY_MODEL_0807f7ee85cf4ac387c3497b4aa6d06f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2cf0afc6b55b4544953eed5a2dbe89c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ececab8a11740658ca3accf95cc5c92",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34acf2ee779c4ce8814da12fada60362",
            "value": 3
          }
        },
        "37b6560af5094e9a9127b604b53120d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7bcb98204b49f59982634bedcd6644",
            "placeholder": "​",
            "style": "IPY_MODEL_b39f007335834df783adf8d3188ee785",
            "value": " 3/3 [00:03&lt;00:00,  1.01it/s]"
          }
        },
        "17ec49acb79b481ab2a31d07d022aafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731755722d05494bb560560ab63685f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0807f7ee85cf4ac387c3497b4aa6d06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ececab8a11740658ca3accf95cc5c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34acf2ee779c4ce8814da12fada60362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba7bcb98204b49f59982634bedcd6644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39f007335834df783adf8d3188ee785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412aa7d7c5d14c3db5180536f5e65cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70a99f16b4043b6964c75846bb03a58",
              "IPY_MODEL_11f753b2b8bf4073b081b0897c409d73",
              "IPY_MODEL_0a8fdd7b3ca94068b93d2b55e60da237"
            ],
            "layout": "IPY_MODEL_e8ed8689ae8541cb967b9e8d87b019fb"
          }
        },
        "f70a99f16b4043b6964c75846bb03a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_631e6c5c9ba642c5ade7f78908841d40",
            "placeholder": "​",
            "style": "IPY_MODEL_9c89ae10c08649ceb56e029a4c00ddff",
            "value": "generation_config.json: 100%"
          }
        },
        "11f753b2b8bf4073b081b0897c409d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c0f844e34046faaf77f39b751089ed",
            "max": 237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e83b8fce047a4b7da8a706b4434dcf26",
            "value": 237
          }
        },
        "0a8fdd7b3ca94068b93d2b55e60da237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e7a2d3218b42879f987046e7f05b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec2ca02fc984d5d8216f2e17ea9d3da",
            "value": " 237/237 [00:00&lt;00:00, 27.0kB/s]"
          }
        },
        "e8ed8689ae8541cb967b9e8d87b019fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631e6c5c9ba642c5ade7f78908841d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c89ae10c08649ceb56e029a4c00ddff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35c0f844e34046faaf77f39b751089ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83b8fce047a4b7da8a706b4434dcf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e7a2d3218b42879f987046e7f05b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec2ca02fc984d5d8216f2e17ea9d3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b6ad05b51324f4d8cf917639ac05219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3887493b5b28491882ac326488752c56",
              "IPY_MODEL_9f19e86f0ac846a6a63945af3282e217",
              "IPY_MODEL_b1c72abe653645eb8419337a2dbfb89b"
            ],
            "layout": "IPY_MODEL_fc2ed50f55654687ac99a83ce54bf2fd"
          }
        },
        "3887493b5b28491882ac326488752c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942aec1327ae4f99958c4485dc58a901",
            "placeholder": "​",
            "style": "IPY_MODEL_a9eebc847c7440b292dd73fc4a37c600",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9f19e86f0ac846a6a63945af3282e217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6e8128984743f1bd9e20d39984dc7e",
            "max": 10534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95206c1737024c6bb678325b5c9b6fd7",
            "value": 10534
          }
        },
        "b1c72abe653645eb8419337a2dbfb89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa3d5ab429d24f60893720f607071034",
            "placeholder": "​",
            "style": "IPY_MODEL_50b95c105546401c992d7bf3ea7be123",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "fc2ed50f55654687ac99a83ce54bf2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942aec1327ae4f99958c4485dc58a901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9eebc847c7440b292dd73fc4a37c600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d6e8128984743f1bd9e20d39984dc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95206c1737024c6bb678325b5c9b6fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa3d5ab429d24f60893720f607071034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b95c105546401c992d7bf3ea7be123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d69942eb3c445209740cfa19ecb1797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58d209bdb5314454b12b54d2d413bf28",
              "IPY_MODEL_69df914604eb4551b20d11845620e6ed",
              "IPY_MODEL_e90569b2d7c0407394b78636a462c83e"
            ],
            "layout": "IPY_MODEL_7606ef88b82f4922b5d0d1e674007c08"
          }
        },
        "58d209bdb5314454b12b54d2d413bf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4d8fc03f7a41d9bfa34143932b04cd",
            "placeholder": "​",
            "style": "IPY_MODEL_8b468070150d477d9e181141aab56619",
            "value": "vocab.json: 100%"
          }
        },
        "69df914604eb4551b20d11845620e6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e652a3c42046f796917e8d3ec42e53",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ba1beaceeab47d78f7f4bc1cea8a1a3",
            "value": 2776833
          }
        },
        "e90569b2d7c0407394b78636a462c83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18337c0aa9474eb3b6c00ddac8d35052",
            "placeholder": "​",
            "style": "IPY_MODEL_95e86e3188fe48f7bd8574b321a1a9c1",
            "value": " 2.78M/2.78M [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "7606ef88b82f4922b5d0d1e674007c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b4d8fc03f7a41d9bfa34143932b04cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b468070150d477d9e181141aab56619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e652a3c42046f796917e8d3ec42e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba1beaceeab47d78f7f4bc1cea8a1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18337c0aa9474eb3b6c00ddac8d35052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e86e3188fe48f7bd8574b321a1a9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "387c3c25d5d54518a3281cf864a59253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cdcee73624440e8a9cba0c12f634d79",
              "IPY_MODEL_9ebbe1f8e7874c60b9fccd05432c7f8d",
              "IPY_MODEL_df36a1e90f45496d85baa36587c46cfb"
            ],
            "layout": "IPY_MODEL_4f00b7156f884d968a0161d078832ddd"
          }
        },
        "0cdcee73624440e8a9cba0c12f634d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e060bdb0085842ca95f2042cad4c4dc4",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa0273f0c3e4554926b43c74abdf271",
            "value": "merges.txt: 100%"
          }
        },
        "9ebbe1f8e7874c60b9fccd05432c7f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aebc42e40c95473981e5a38171bd409d",
            "max": 1671853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c35c5eddd8f341aab0fa22976e1c161d",
            "value": 1671853
          }
        },
        "df36a1e90f45496d85baa36587c46cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bab2e7ce0e74f8ab3e02340f822f129",
            "placeholder": "​",
            "style": "IPY_MODEL_a14f68b055ce4c2fbc6f6234e18ae0bb",
            "value": " 1.67M/1.67M [00:00&lt;00:00, 8.15MB/s]"
          }
        },
        "4f00b7156f884d968a0161d078832ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e060bdb0085842ca95f2042cad4c4dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa0273f0c3e4554926b43c74abdf271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aebc42e40c95473981e5a38171bd409d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35c5eddd8f341aab0fa22976e1c161d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bab2e7ce0e74f8ab3e02340f822f129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14f68b055ce4c2fbc6f6234e18ae0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e478fe319fb4ae3bed2d693294d1ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1ec6c5f19d440d1a11254ed11fb0541",
              "IPY_MODEL_d17454b350294663946354c9769946e9",
              "IPY_MODEL_f5329f92b7d14439b912a34567e6f197"
            ],
            "layout": "IPY_MODEL_bbc93746c71d4977b9ea1c6e3da57b25"
          }
        },
        "f1ec6c5f19d440d1a11254ed11fb0541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3472067a25354e3bb254d0b828aa16b7",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa348307a2744ce8b7121d658595140",
            "value": "added_tokens.json: 100%"
          }
        },
        "d17454b350294663946354c9769946e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b448e134bad4e02bddb080c498b4c2b",
            "max": 707,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efed608a937448dcae4394a7d32ec483",
            "value": 707
          }
        },
        "f5329f92b7d14439b912a34567e6f197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3f25aac1ed8420284e8dea74ef51a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_109b2bdf072e4f0fb42b6752f51ba681",
            "value": " 707/707 [00:00&lt;00:00, 93.1kB/s]"
          }
        },
        "bbc93746c71d4977b9ea1c6e3da57b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3472067a25354e3bb254d0b828aa16b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa348307a2744ce8b7121d658595140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b448e134bad4e02bddb080c498b4c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efed608a937448dcae4394a7d32ec483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3f25aac1ed8420284e8dea74ef51a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109b2bdf072e4f0fb42b6752f51ba681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b97cd0ed7db94161a3d00156d6293a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84583d3d604148cf9e1534b2a23d71f5",
              "IPY_MODEL_e0bbc4e1434d4ba38e4f689aacdb462a",
              "IPY_MODEL_26ffee56cf6b427491260d802b362661"
            ],
            "layout": "IPY_MODEL_918d0058954e431caf66b8606d5aebc8"
          }
        },
        "84583d3d604148cf9e1534b2a23d71f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90818c67eb1e4e089813e3aa2a90937b",
            "placeholder": "​",
            "style": "IPY_MODEL_e5f78f851e9b47fda90030a286e05f64",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e0bbc4e1434d4ba38e4f689aacdb462a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35dd949f7f5c4abe8ee61c79e3e4f8ec",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b083aeac5eab48dc929b3fef4766ba6e",
            "value": 614
          }
        },
        "26ffee56cf6b427491260d802b362661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b31d85081a1e4d39a66c1a52d818ff34",
            "placeholder": "​",
            "style": "IPY_MODEL_c38bd04b6d0748efa745ab43d24b3f56",
            "value": " 614/614 [00:00&lt;00:00, 78.6kB/s]"
          }
        },
        "918d0058954e431caf66b8606d5aebc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90818c67eb1e4e089813e3aa2a90937b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f78f851e9b47fda90030a286e05f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35dd949f7f5c4abe8ee61c79e3e4f8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b083aeac5eab48dc929b3fef4766ba6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b31d85081a1e4d39a66c1a52d818ff34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38bd04b6d0748efa745ab43d24b3f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a13994288f7841768adfcd4f5bec0ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6645b35c585400b830047f4c1671da4",
              "IPY_MODEL_554df2f7f9ff4410ae2f273dfd4fd5c2",
              "IPY_MODEL_4cef2a7eb7864c41997c93425f60186a"
            ],
            "layout": "IPY_MODEL_6654583786fd4a6b8e7b75e68e9289e0"
          }
        },
        "c6645b35c585400b830047f4c1671da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9931b6b98f394e729813d473f6c705fe",
            "placeholder": "​",
            "style": "IPY_MODEL_19c20b68857247f19a3b63cfee7904fe",
            "value": "tokenizer.json: 100%"
          }
        },
        "554df2f7f9ff4410ae2f273dfd4fd5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f2625fa0494b84857dab15dae8019b",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b3312b4102a4f8aa802855ff2cb2ddd",
            "value": 11422654
          }
        },
        "4cef2a7eb7864c41997c93425f60186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a32423ce0d412f97dc677e4b488e48",
            "placeholder": "​",
            "style": "IPY_MODEL_79b7aa9a344e48f78db3d0783b40620a",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 6.14MB/s]"
          }
        },
        "6654583786fd4a6b8e7b75e68e9289e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9931b6b98f394e729813d473f6c705fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c20b68857247f19a3b63cfee7904fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60f2625fa0494b84857dab15dae8019b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3312b4102a4f8aa802855ff2cb2ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74a32423ce0d412f97dc677e4b488e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b7aa9a344e48f78db3d0783b40620a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "469b28fb26304b579acb9449e3e9119e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e40fad30e08141a5bd9e38621b08da18",
              "IPY_MODEL_a6d829b1ae4a4ef3af8e0e806751db2c",
              "IPY_MODEL_9d67ef9f885f4b1c90301f1f27326d29"
            ],
            "layout": "IPY_MODEL_c3034c4ebabb493a9b2c8b44c2f9e4c8"
          }
        },
        "e40fad30e08141a5bd9e38621b08da18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be629eb882644b29fa1373de50b1a8a",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fbbc906ad845a484918779c9dc86a3",
            "value": "chat_template.jinja: 100%"
          }
        },
        "a6d829b1ae4a4ef3af8e0e806751db2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a4815a9dbba42b0a8114c7b095e46a0",
            "max": 4673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5f3426c1b674bbca0b6f5050767dd90",
            "value": 4673
          }
        },
        "9d67ef9f885f4b1c90301f1f27326d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4e48aa7e7a41f188db36417a68b2f4",
            "placeholder": "​",
            "style": "IPY_MODEL_3a85ada3e4fb4785b5709a944a40d0d1",
            "value": " 4.67k/4.67k [00:00&lt;00:00, 606kB/s]"
          }
        },
        "c3034c4ebabb493a9b2c8b44c2f9e4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be629eb882644b29fa1373de50b1a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fbbc906ad845a484918779c9dc86a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a4815a9dbba42b0a8114c7b095e46a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f3426c1b674bbca0b6f5050767dd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b4e48aa7e7a41f188db36417a68b2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a85ada3e4fb4785b5709a944a40d0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3523c60752460d822472a23e895302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_566fdf30687145bea8be3d2be95dece8",
              "IPY_MODEL_732b933970e64a98a0a560b9939cb657",
              "IPY_MODEL_0d0bc4cdf7b04383af9569f0efa2a59f"
            ],
            "layout": "IPY_MODEL_d6c68aa0bbf14a79a7e0f60fad386810"
          }
        },
        "566fdf30687145bea8be3d2be95dece8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e63992f1764b17a1ff1c0381ea8714",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3d2d0b243a42b18d43e99b92bf0b06",
            "value": "Map: 100%"
          }
        },
        "732b933970e64a98a0a560b9939cb657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91787debf964f63a3e7e38d28e5d706",
            "max": 19252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7581599d67b4426798959f6053e0b877",
            "value": 19252
          }
        },
        "0d0bc4cdf7b04383af9569f0efa2a59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a6cbfa63c94413af02136f46975f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_9f0be20c3d0b460bbdc5219ab89ccc46",
            "value": " 19252/19252 [00:01&lt;00:00, 13938.16 examples/s]"
          }
        },
        "d6c68aa0bbf14a79a7e0f60fad386810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e63992f1764b17a1ff1c0381ea8714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3d2d0b243a42b18d43e99b92bf0b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91787debf964f63a3e7e38d28e5d706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7581599d67b4426798959f6053e0b877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94a6cbfa63c94413af02136f46975f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0be20c3d0b460bbdc5219ab89ccc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8953dbdb6d3f46989af4594aac66349c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38419feaa7a648279550433138c8f83a",
              "IPY_MODEL_7160a2e68f32454785d0b2dab7cd873e",
              "IPY_MODEL_0e8d6c36d97d4dc89afccce13f255bdb"
            ],
            "layout": "IPY_MODEL_1e95be423d7a45f7b28de96a105f717c"
          }
        },
        "38419feaa7a648279550433138c8f83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0eafb8bd2804fd18fb06ec6ff884547",
            "placeholder": "​",
            "style": "IPY_MODEL_93cd651128734950b7da91433ae7f1c5",
            "value": "Unsloth: Standardizing formats (num_proc=12): 100%"
          }
        },
        "7160a2e68f32454785d0b2dab7cd873e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13174e0128594793b181f40bf2b9c0b7",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdbd6e69d11143b4928ce87521d1bbb6",
            "value": 100000
          }
        },
        "0e8d6c36d97d4dc89afccce13f255bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8cba83676c462ba9fdb0eefcc14c6d",
            "placeholder": "​",
            "style": "IPY_MODEL_16785e1b38734aa9ad2573049568fa11",
            "value": " 100000/100000 [00:01&lt;00:00, 143285.88 examples/s]"
          }
        },
        "1e95be423d7a45f7b28de96a105f717c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0eafb8bd2804fd18fb06ec6ff884547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cd651128734950b7da91433ae7f1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13174e0128594793b181f40bf2b9c0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdbd6e69d11143b4928ce87521d1bbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af8cba83676c462ba9fdb0eefcc14c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16785e1b38734aa9ad2573049568fa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2924a4b08a6b4b1f973e7a2a7b619da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b22756144c1b4f78959a3e98a42865d6",
              "IPY_MODEL_19b2b0b38f4241caa8a6a39f2807c5ac",
              "IPY_MODEL_588f89071f154c54a65d2cab0ec781d8"
            ],
            "layout": "IPY_MODEL_9b9e6570047f42b8b1203d977e8f81f9"
          }
        },
        "b22756144c1b4f78959a3e98a42865d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858fa2e2fa5f444b9aa24ecacb2eda6b",
            "placeholder": "​",
            "style": "IPY_MODEL_829d4ecccd014a4ea0dc75cd5ade9388",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=12): 100%"
          }
        },
        "19b2b0b38f4241caa8a6a39f2807c5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb72d7c91b6743f78397da55a197c005",
            "max": 25669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c4b0e55869f485682efd901cf12b3c2",
            "value": 25669
          }
        },
        "588f89071f154c54a65d2cab0ec781d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad5f303286a48dd9a74877e66998aef",
            "placeholder": "​",
            "style": "IPY_MODEL_4396a9bab5004f3585118ca908cb1e78",
            "value": " 25669/25669 [00:54&lt;00:00, 484.34 examples/s]"
          }
        },
        "9b9e6570047f42b8b1203d977e8f81f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858fa2e2fa5f444b9aa24ecacb2eda6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829d4ecccd014a4ea0dc75cd5ade9388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb72d7c91b6743f78397da55a197c005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4b0e55869f485682efd901cf12b3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ad5f303286a48dd9a74877e66998aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4396a9bab5004f3585118ca908cb1e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvKKU8i_jpMT",
        "outputId": "c0cfa7c6-4c9f-4e62-d907-af658a55b87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 22 21:38:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   34C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "EvdvDBY8kDru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "NY8HyRfpk_go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-14B\",\n",
        "    max_seq_length = 2048,   # Context length - can be longer, but uses more memory\n",
        "    load_in_4bit = True,     # 4bit uses much less memory\n",
        "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # We have full finetuning now!\n",
        "    # token = \"hf_...\",      # use one if using gated models\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "3b7e4612a43e499c903e01605700af50",
            "97ea316964874edda0810f679c9a457c",
            "c00b126e19e64326b8f1b91dfd2c1266",
            "c54d7b1ac44a47ad985e3af578df5fa9",
            "74c6a6c732a94553ba1ef32ba66981fe",
            "e62cec7bd8d045dc8c9045943bc38f07",
            "cb9b5946f45644e2bef623895d0f2009",
            "83958d5a3a954e0da7f04347900b3904",
            "37adfac928204953998ab02d8c90ddc4",
            "aa5194bdf323471b97048546627f74cc",
            "155c099faaa141758b66995f1092dce3",
            "55cc1ecd24134f08bb7511e9298fae0e",
            "b7e758bc27bd4f389f67f3461b94985c",
            "03310292fb2b40c8b2fd3b53591202da",
            "330037291a2245faa69f90f67c52f534",
            "04df8c29e56a4894991cec7360cabdc7",
            "50762926df0f4e259724c80ec5af6ba0",
            "c9f3d6effdd8453399cd33d1faed1e5b",
            "148559f8e57242ca8aa6bdac0354f1ce",
            "d59fb6a333244acca86df182a5cb02b4",
            "f05b6289ebe146eaa86acf3bbdc8df84",
            "f2ecb5e835244ecca03f4821e773b33e",
            "cf52ec753ffe49d9bb43234988662bc5",
            "83903f3f783842bb81df068217e0e71f",
            "1073f86287e94c6b807e2f4355646422",
            "5317ad3fdfb246a1bb0dd08eac8bad3e",
            "5fe137895099446d9c336cb73d72be8a",
            "03c7eaea87434c7696a9d5d528a1d17c",
            "cb1402d028554e22ae0f75e37412dca2",
            "338ba8971e3f4fdba128948ee260fb5a",
            "f1f5d9ce022140228d17e113c6e75785",
            "14cba64ec8584dc49a1ee6a61c164acf",
            "6a03ec4fb2eb400f998a498604e988ae",
            "2be26f25f73b4a818ec5cb1539a04025",
            "fe5c549b8647457fbf5df03ac28919df",
            "d3b24e8951dc4fca94958d89abaa14cf",
            "ad00552793764af19224a469a3aa7c61",
            "9b5722e538ad4c269a82970dd391a17c",
            "f50fde704eb34472b9543ecd5ca1a464",
            "db7d8870ceee438e8d516c1ee95b721d",
            "033e975dddc744888dd4c2e0c30a3cb5",
            "5239e420f4b648da8dae632d6eb60cf8",
            "7ddb1b13366c4e75b214ecf5c5772ed1",
            "9f09248028674aeaad1fd458c22883ec",
            "bc7182d4f81d47baacb7c1d9767ee8e7",
            "115efb345de24148930316c7dd14ab87",
            "2cf0afc6b55b4544953eed5a2dbe89c0",
            "37b6560af5094e9a9127b604b53120d7",
            "17ec49acb79b481ab2a31d07d022aafa",
            "731755722d05494bb560560ab63685f8",
            "0807f7ee85cf4ac387c3497b4aa6d06f",
            "2ececab8a11740658ca3accf95cc5c92",
            "34acf2ee779c4ce8814da12fada60362",
            "ba7bcb98204b49f59982634bedcd6644",
            "b39f007335834df783adf8d3188ee785",
            "412aa7d7c5d14c3db5180536f5e65cb0",
            "f70a99f16b4043b6964c75846bb03a58",
            "11f753b2b8bf4073b081b0897c409d73",
            "0a8fdd7b3ca94068b93d2b55e60da237",
            "e8ed8689ae8541cb967b9e8d87b019fb",
            "631e6c5c9ba642c5ade7f78908841d40",
            "9c89ae10c08649ceb56e029a4c00ddff",
            "35c0f844e34046faaf77f39b751089ed",
            "e83b8fce047a4b7da8a706b4434dcf26",
            "f4e7a2d3218b42879f987046e7f05b4a",
            "5ec2ca02fc984d5d8216f2e17ea9d3da",
            "4b6ad05b51324f4d8cf917639ac05219",
            "3887493b5b28491882ac326488752c56",
            "9f19e86f0ac846a6a63945af3282e217",
            "b1c72abe653645eb8419337a2dbfb89b",
            "fc2ed50f55654687ac99a83ce54bf2fd",
            "942aec1327ae4f99958c4485dc58a901",
            "a9eebc847c7440b292dd73fc4a37c600",
            "7d6e8128984743f1bd9e20d39984dc7e",
            "95206c1737024c6bb678325b5c9b6fd7",
            "aa3d5ab429d24f60893720f607071034",
            "50b95c105546401c992d7bf3ea7be123",
            "1d69942eb3c445209740cfa19ecb1797",
            "58d209bdb5314454b12b54d2d413bf28",
            "69df914604eb4551b20d11845620e6ed",
            "e90569b2d7c0407394b78636a462c83e",
            "7606ef88b82f4922b5d0d1e674007c08",
            "5b4d8fc03f7a41d9bfa34143932b04cd",
            "8b468070150d477d9e181141aab56619",
            "c3e652a3c42046f796917e8d3ec42e53",
            "4ba1beaceeab47d78f7f4bc1cea8a1a3",
            "18337c0aa9474eb3b6c00ddac8d35052",
            "95e86e3188fe48f7bd8574b321a1a9c1",
            "387c3c25d5d54518a3281cf864a59253",
            "0cdcee73624440e8a9cba0c12f634d79",
            "9ebbe1f8e7874c60b9fccd05432c7f8d",
            "df36a1e90f45496d85baa36587c46cfb",
            "4f00b7156f884d968a0161d078832ddd",
            "e060bdb0085842ca95f2042cad4c4dc4",
            "6fa0273f0c3e4554926b43c74abdf271",
            "aebc42e40c95473981e5a38171bd409d",
            "c35c5eddd8f341aab0fa22976e1c161d",
            "4bab2e7ce0e74f8ab3e02340f822f129",
            "a14f68b055ce4c2fbc6f6234e18ae0bb",
            "1e478fe319fb4ae3bed2d693294d1ef7",
            "f1ec6c5f19d440d1a11254ed11fb0541",
            "d17454b350294663946354c9769946e9",
            "f5329f92b7d14439b912a34567e6f197",
            "bbc93746c71d4977b9ea1c6e3da57b25",
            "3472067a25354e3bb254d0b828aa16b7",
            "5aa348307a2744ce8b7121d658595140",
            "5b448e134bad4e02bddb080c498b4c2b",
            "efed608a937448dcae4394a7d32ec483",
            "f3f25aac1ed8420284e8dea74ef51a4a",
            "109b2bdf072e4f0fb42b6752f51ba681",
            "b97cd0ed7db94161a3d00156d6293a4b",
            "84583d3d604148cf9e1534b2a23d71f5",
            "e0bbc4e1434d4ba38e4f689aacdb462a",
            "26ffee56cf6b427491260d802b362661",
            "918d0058954e431caf66b8606d5aebc8",
            "90818c67eb1e4e089813e3aa2a90937b",
            "e5f78f851e9b47fda90030a286e05f64",
            "35dd949f7f5c4abe8ee61c79e3e4f8ec",
            "b083aeac5eab48dc929b3fef4766ba6e",
            "b31d85081a1e4d39a66c1a52d818ff34",
            "c38bd04b6d0748efa745ab43d24b3f56",
            "a13994288f7841768adfcd4f5bec0ef9",
            "c6645b35c585400b830047f4c1671da4",
            "554df2f7f9ff4410ae2f273dfd4fd5c2",
            "4cef2a7eb7864c41997c93425f60186a",
            "6654583786fd4a6b8e7b75e68e9289e0",
            "9931b6b98f394e729813d473f6c705fe",
            "19c20b68857247f19a3b63cfee7904fe",
            "60f2625fa0494b84857dab15dae8019b",
            "7b3312b4102a4f8aa802855ff2cb2ddd",
            "74a32423ce0d412f97dc677e4b488e48",
            "79b7aa9a344e48f78db3d0783b40620a",
            "469b28fb26304b579acb9449e3e9119e",
            "e40fad30e08141a5bd9e38621b08da18",
            "a6d829b1ae4a4ef3af8e0e806751db2c",
            "9d67ef9f885f4b1c90301f1f27326d29",
            "c3034c4ebabb493a9b2c8b44c2f9e4c8",
            "8be629eb882644b29fa1373de50b1a8a",
            "f2fbbc906ad845a484918779c9dc86a3",
            "6a4815a9dbba42b0a8114c7b095e46a0",
            "b5f3426c1b674bbca0b6f5050767dd90",
            "8b4e48aa7e7a41f188db36417a68b2f4",
            "3a85ada3e4fb4785b5709a944a40d0d1"
          ]
        },
        "id": "nVmKdvWmlRIz",
        "outputId": "a3a0af8d-3e09-4993-92ad-780d20fb1286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.6.5: Fast Qwen3 patching. Transformers: 4.52.4.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:222: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/168k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b7e4612a43e499c903e01605700af50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55cc1ecd24134f08bb7511e9298fae0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf52ec753ffe49d9bb43234988662bc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2be26f25f73b4a818ec5cb1539a04025"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc7182d4f81d47baacb7c1d9767ee8e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "412aa7d7c5d14c3db5180536f5e65cb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b6ad05b51324f4d8cf917639ac05219"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d69942eb3c445209740cfa19ecb1797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "387c3c25d5d54518a3281cf864a59253"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e478fe319fb4ae3bed2d693294d1ef7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b97cd0ed7db94161a3d00156d6293a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a13994288f7841768adfcd4f5bec0ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja:   0%|          | 0.00/4.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469b28fb26304b579acb9449e3e9119e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.named_modules())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzoyoqmcmLIm",
        "outputId": "5b146e74-898a-4ece-f49e-bab0527dab47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  Qwen3ForCausalLM(\n",
              "    (model): Qwen3Model(\n",
              "      (embed_tokens): Embedding(151936, 5120, padding_idx=151654)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (6): Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (7-18): 12 x Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (19): Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (20-37): 18 x Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (38): Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "        (39): Qwen3DecoderLayer(\n",
              "          (self_attn): Qwen3Attention(\n",
              "            (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "            (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "          (mlp): Qwen3MLP(\n",
              "            (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "            (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "          (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        )\n",
              "      )\n",
              "      (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
              "  )),\n",
              " ('model',\n",
              "  Qwen3Model(\n",
              "    (embed_tokens): Embedding(151936, 5120, padding_idx=151654)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (6): Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (7-18): 12 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (19): Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (20-37): 18 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (38): Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "      (39): Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.embed_tokens', Embedding(151936, 5120, padding_idx=151654)),\n",
              " ('model.layers',\n",
              "  ModuleList(\n",
              "    (0-5): 6 x Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (6): Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (7-18): 12 x Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (19): Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (20-37): 18 x Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (38): Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "    (39): Qwen3DecoderLayer(\n",
              "      (self_attn): Qwen3Attention(\n",
              "        (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "        (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (mlp): Qwen3MLP(\n",
              "        (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "        (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "        (act_fn): SiLU()\n",
              "      )\n",
              "      (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "      (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    )\n",
              "  )),\n",
              " ('model.layers.0',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.0.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.0.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.0.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.0.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.0.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.0.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.0.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.0.self_attn.rotary_emb', LlamaRotaryEmbedding()),\n",
              " ('model.layers.0.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.0.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.0.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.0.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.0.mlp.act_fn', SiLU()),\n",
              " ('model.layers.0.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.0.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.1',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.1.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.1.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.1.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.1.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.1.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.1.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.1.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.1.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.1.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.1.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.1.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.1.mlp.act_fn', SiLU()),\n",
              " ('model.layers.1.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.1.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.2',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.2.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.2.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.2.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.2.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.2.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.2.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.2.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.2.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.2.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.2.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.2.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.2.mlp.act_fn', SiLU()),\n",
              " ('model.layers.2.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.2.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.3',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.3.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.3.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.3.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.3.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.3.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.3.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.3.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.3.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.3.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.3.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.3.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.3.mlp.act_fn', SiLU()),\n",
              " ('model.layers.3.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.3.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.4',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.4.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.4.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.4.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.4.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.4.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.4.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.4.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.4.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.4.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.4.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.4.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.4.mlp.act_fn', SiLU()),\n",
              " ('model.layers.4.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.4.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.5',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.5.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.5.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.5.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.5.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.5.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.5.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.5.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.5.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.5.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.5.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.5.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.5.mlp.act_fn', SiLU()),\n",
              " ('model.layers.5.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.5.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.6',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.6.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.6.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.6.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.6.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.6.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.6.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.6.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.6.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.6.mlp.gate_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.6.mlp.up_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.6.mlp.down_proj',\n",
              "  Linear(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.6.mlp.act_fn', SiLU()),\n",
              " ('model.layers.6.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.6.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.7',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.7.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.7.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.7.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.7.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.7.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.7.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.7.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.7.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.7.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.7.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.7.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.7.mlp.act_fn', SiLU()),\n",
              " ('model.layers.7.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.7.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.8',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.8.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.8.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.8.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.8.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.8.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.8.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.8.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.8.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.8.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.8.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.8.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.8.mlp.act_fn', SiLU()),\n",
              " ('model.layers.8.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.8.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.9',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.9.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.9.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.9.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.9.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.9.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.9.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.9.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.9.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.9.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.9.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.9.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.9.mlp.act_fn', SiLU()),\n",
              " ('model.layers.9.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.9.post_attention_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.10',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.10.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.10.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.10.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.10.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.10.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.10.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.10.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.10.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.10.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.10.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.10.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.10.mlp.act_fn', SiLU()),\n",
              " ('model.layers.10.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.10.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.11',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.11.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.11.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.11.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.11.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.11.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.11.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.11.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.11.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.11.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.11.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.11.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.11.mlp.act_fn', SiLU()),\n",
              " ('model.layers.11.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.11.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.12',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.12.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.12.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.12.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.12.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.12.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.12.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.12.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.12.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.12.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.12.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.12.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.12.mlp.act_fn', SiLU()),\n",
              " ('model.layers.12.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.12.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.13',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.13.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.13.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.13.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.13.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.13.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.13.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.13.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.13.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.13.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.13.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.13.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.13.mlp.act_fn', SiLU()),\n",
              " ('model.layers.13.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.13.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.14',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.14.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.14.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.14.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.14.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.14.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.14.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.14.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.14.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.14.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.14.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.14.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.14.mlp.act_fn', SiLU()),\n",
              " ('model.layers.14.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.14.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.15',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.15.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.15.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.15.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.15.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.15.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.15.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.15.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.15.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.15.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.15.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.15.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.15.mlp.act_fn', SiLU()),\n",
              " ('model.layers.15.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.15.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.16',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.16.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.16.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.16.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.16.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.16.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.16.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.16.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.16.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.16.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.16.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.16.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.16.mlp.act_fn', SiLU()),\n",
              " ('model.layers.16.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.16.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.17',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.17.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.17.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.17.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.17.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.17.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.17.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.17.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.17.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.17.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.17.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.17.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.17.mlp.act_fn', SiLU()),\n",
              " ('model.layers.17.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.17.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.18',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.18.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.18.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.18.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.18.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.18.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.18.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.18.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.18.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.18.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.18.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.18.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.18.mlp.act_fn', SiLU()),\n",
              " ('model.layers.18.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.18.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.19',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.19.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.19.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.19.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.19.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.19.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.19.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.19.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.19.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.19.mlp.gate_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.19.mlp.up_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.19.mlp.down_proj',\n",
              "  Linear(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.19.mlp.act_fn', SiLU()),\n",
              " ('model.layers.19.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.19.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.20',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.20.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.20.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.20.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.20.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.20.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.20.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.20.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.20.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.20.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.20.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.20.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.20.mlp.act_fn', SiLU()),\n",
              " ('model.layers.20.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.20.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.21',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.21.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.21.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.21.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.21.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.21.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.21.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.21.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.21.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.21.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.21.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.21.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.21.mlp.act_fn', SiLU()),\n",
              " ('model.layers.21.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.21.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.22',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.22.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.22.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.22.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.22.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.22.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.22.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.22.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.22.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.22.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.22.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.22.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.22.mlp.act_fn', SiLU()),\n",
              " ('model.layers.22.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.22.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.23',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.23.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.23.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.23.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.23.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.23.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.23.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.23.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.23.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.23.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.23.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.23.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.23.mlp.act_fn', SiLU()),\n",
              " ('model.layers.23.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.23.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.24',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.24.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.24.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.24.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.24.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.24.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.24.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.24.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.24.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.24.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.24.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.24.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.24.mlp.act_fn', SiLU()),\n",
              " ('model.layers.24.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.24.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.25',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.25.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.25.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.25.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.25.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.25.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.25.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.25.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.25.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.25.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.25.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.25.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.25.mlp.act_fn', SiLU()),\n",
              " ('model.layers.25.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.25.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.26',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.26.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.26.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.26.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.26.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.26.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.26.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.26.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.26.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.26.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.26.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.26.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.26.mlp.act_fn', SiLU()),\n",
              " ('model.layers.26.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.26.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.27',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.27.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.27.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.27.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.27.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.27.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.27.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.27.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.27.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.27.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.27.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.27.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.27.mlp.act_fn', SiLU()),\n",
              " ('model.layers.27.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.27.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.28',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.28.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.28.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.28.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.28.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.28.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.28.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.28.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.28.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.28.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.28.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.28.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.28.mlp.act_fn', SiLU()),\n",
              " ('model.layers.28.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.28.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.29',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.29.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.29.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.29.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.29.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.29.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.29.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.29.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.29.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.29.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.29.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.29.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.29.mlp.act_fn', SiLU()),\n",
              " ('model.layers.29.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.29.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.30',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.30.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.30.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.30.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.30.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.30.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.30.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.30.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.30.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.30.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.30.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.30.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.30.mlp.act_fn', SiLU()),\n",
              " ('model.layers.30.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.30.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.31',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.31.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.31.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.31.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.31.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.31.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.31.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.31.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.31.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.31.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.31.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.31.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.31.mlp.act_fn', SiLU()),\n",
              " ('model.layers.31.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.31.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.32',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.32.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.32.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.32.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.32.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.32.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.32.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.32.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.32.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.32.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.32.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.32.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.32.mlp.act_fn', SiLU()),\n",
              " ('model.layers.32.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.32.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.33',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.33.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.33.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.33.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.33.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.33.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.33.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.33.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.33.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.33.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.33.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.33.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.33.mlp.act_fn', SiLU()),\n",
              " ('model.layers.33.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.33.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.34',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.34.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.34.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.34.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.34.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.34.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.34.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.34.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.34.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.34.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.34.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.34.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.34.mlp.act_fn', SiLU()),\n",
              " ('model.layers.34.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.34.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.35',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.35.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.35.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.35.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.35.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.35.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.35.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.35.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.35.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.35.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.35.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.35.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.35.mlp.act_fn', SiLU()),\n",
              " ('model.layers.35.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.35.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.36',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.36.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.36.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.36.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.36.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.36.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.36.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.36.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.36.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.36.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.36.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.36.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.36.mlp.act_fn', SiLU()),\n",
              " ('model.layers.36.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.36.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.37',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.37.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.37.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.37.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.37.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.37.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.37.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.37.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.37.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.37.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.37.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.37.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.37.mlp.act_fn', SiLU()),\n",
              " ('model.layers.37.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.37.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.38',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.38.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.38.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.38.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.38.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.38.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.38.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.38.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.38.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.38.mlp.gate_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.38.mlp.up_proj',\n",
              "  Linear(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.38.mlp.down_proj',\n",
              "  Linear(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.38.mlp.act_fn', SiLU()),\n",
              " ('model.layers.38.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.38.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.39',\n",
              "  Qwen3DecoderLayer(\n",
              "    (self_attn): Qwen3Attention(\n",
              "      (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "      (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "      (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (mlp): Qwen3MLP(\n",
              "      (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "      (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "      (act_fn): SiLU()\n",
              "    )\n",
              "    (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "    (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
              "  )),\n",
              " ('model.layers.39.self_attn',\n",
              "  Qwen3Attention(\n",
              "    (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (k_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (v_proj): Linear4bit(in_features=5120, out_features=1024, bias=False)\n",
              "    (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "    (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )),\n",
              " ('model.layers.39.self_attn.q_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.39.self_attn.k_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.39.self_attn.v_proj',\n",
              "  Linear4bit(in_features=5120, out_features=1024, bias=False)),\n",
              " ('model.layers.39.self_attn.o_proj',\n",
              "  Linear4bit(in_features=5120, out_features=5120, bias=False)),\n",
              " ('model.layers.39.self_attn.q_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.39.self_attn.k_norm', Qwen3RMSNorm((128,), eps=1e-06)),\n",
              " ('model.layers.39.mlp',\n",
              "  Qwen3MLP(\n",
              "    (gate_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (up_proj): Linear4bit(in_features=5120, out_features=17408, bias=False)\n",
              "    (down_proj): Linear4bit(in_features=17408, out_features=5120, bias=False)\n",
              "    (act_fn): SiLU()\n",
              "  )),\n",
              " ('model.layers.39.mlp.gate_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.39.mlp.up_proj',\n",
              "  Linear4bit(in_features=5120, out_features=17408, bias=False)),\n",
              " ('model.layers.39.mlp.down_proj',\n",
              "  Linear4bit(in_features=17408, out_features=5120, bias=False)),\n",
              " ('model.layers.39.mlp.act_fn', SiLU()),\n",
              " ('model.layers.39.input_layernorm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.layers.39.post_attention_layernorm',\n",
              "  Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('model.norm', Qwen3RMSNorm((5120,), eps=1e-06)),\n",
              " ('lm_head', Linear(in_features=5120, out_features=151936, bias=False))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIMetqOtlah0",
        "outputId": "f37c9f9c-fb00-45b1-e737-a4174b69cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.6.5 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "reasoning_dataset = load_dataset(\"unsloth/OpenMathReasoning-mini\", split = \"cot\")\n",
        "non_reasoning_dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
      ],
      "metadata": {
        "id": "HUe3ea4FncM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJEgEzP7owaJ",
        "outputId": "decd0aae-0bd8-4779-f110-991a6da031cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_answer': '14',\n",
              " 'problem_type': 'has_answer_extracted',\n",
              " 'problem_source': 'aops_c4_high_school_math',\n",
              " 'generation_model': 'DeepSeek-R1',\n",
              " 'pass_rate_72b_tir': '0.96875',\n",
              " 'problem': 'Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.',\n",
              " 'generated_solution': \"<think>\\nOkay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\n</think>To solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]\",\n",
              " 'inference_mode': 'cot'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_reasoning_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMCwebxCpHCL",
        "outputId": "f70da773-b202-4f4e-9907-1b4fd02ead61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conversations': [{'from': 'human',\n",
              "   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n",
              "  {'from': 'gpt',\n",
              "   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n",
              " 'source': 'infini-instruct-top-500k',\n",
              " 'score': 5.212620735168457}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_conversation(examples):\n",
        "    problems  = examples[\"problem\"]\n",
        "    solutions = examples[\"generated_solution\"]\n",
        "    conversations = []\n",
        "    for problem, solution in zip(problems, solutions):\n",
        "        conversations.append([\n",
        "            {\"role\" : \"user\",      \"content\" : problem},\n",
        "            {\"role\" : \"assistant\", \"content\" : solution},\n",
        "        ])\n",
        "    return { \"conversations\": conversations, }"
      ],
      "metadata": {
        "id": "oHwtuXxZpmFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_conversations = tokenizer.apply_chat_template(\n",
        "    reasoning_dataset.map(generate_conversation, batched = True)[\"conversations\"],\n",
        "    tokenize = False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6b3523c60752460d822472a23e895302",
            "566fdf30687145bea8be3d2be95dece8",
            "732b933970e64a98a0a560b9939cb657",
            "0d0bc4cdf7b04383af9569f0efa2a59f",
            "d6c68aa0bbf14a79a7e0f60fad386810",
            "76e63992f1764b17a1ff1c0381ea8714",
            "fd3d2d0b243a42b18d43e99b92bf0b06",
            "e91787debf964f63a3e7e38d28e5d706",
            "7581599d67b4426798959f6053e0b877",
            "94a6cbfa63c94413af02136f46975f4d",
            "9f0be20c3d0b460bbdc5219ab89ccc46"
          ]
        },
        "id": "dp69fFUkqGJ0",
        "outputId": "4fc2d34b-da0f-4487-8f9d-c31e07018469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19252 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b3523c60752460d822472a23e895302"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_conversation(reasoning_dataset[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7GNVNd-qLhP",
        "outputId": "dd39257b-9039-4664-bb9a-6901d08752d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conversations': [[{'role': 'user',\n",
              "    'content': 'Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.'},\n",
              "   {'role': 'assistant',\n",
              "    'content': \"<think>\\nOkay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\n</think>To solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]\"}]]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_conversations[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Ai_eluqVU9",
        "outputId": "8f08f3ec-f5db-4075-e98c-de3bd67fcaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|im_start|>user\\nGiven $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\n</think>\\n\\nTo solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]<|im_end|>\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "dataset = standardize_sharegpt(non_reasoning_dataset)\n",
        "\n",
        "non_reasoning_conversations = tokenizer.apply_chat_template(\n",
        "    dataset[\"conversations\"],\n",
        "    tokenize = False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8953dbdb6d3f46989af4594aac66349c",
            "38419feaa7a648279550433138c8f83a",
            "7160a2e68f32454785d0b2dab7cd873e",
            "0e8d6c36d97d4dc89afccce13f255bdb",
            "1e95be423d7a45f7b28de96a105f717c",
            "e0eafb8bd2804fd18fb06ec6ff884547",
            "93cd651128734950b7da91433ae7f1c5",
            "13174e0128594793b181f40bf2b9c0b7",
            "cdbd6e69d11143b4928ce87521d1bbb6",
            "af8cba83676c462ba9fdb0eefcc14c6d",
            "16785e1b38734aa9ad2573049568fa11"
          ]
        },
        "id": "Fb1iTQ-Uqe9T",
        "outputId": "1744e0fa-bff8-44a1-ef3c-8dada458d524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=12):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8953dbdb6d3f46989af4594aac66349c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_reasoning_conversations[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "BLoSCwL_q6c-",
        "outputId": "fb4bd9ce-3886-4933-993c-aae3123d5f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>user\\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.<|im_end|>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_percentage = 0.25"
      ],
      "metadata": {
        "id": "gcA4TEIcq_5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_reasoning_subset = pd.Series(non_reasoning_conversations)\n",
        "non_reasoning_subset = non_reasoning_subset.sample(\n",
        "    int(len(reasoning_conversations)*(chat_percentage/(1 - chat_percentage))),\n",
        "    random_state = 2407,\n",
        ")\n",
        "print(len(reasoning_conversations))\n",
        "print(len(non_reasoning_subset))\n",
        "print(len(non_reasoning_subset) / (len(non_reasoning_subset) + len(reasoning_conversations)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZsJoXNdrYPV",
        "outputId": "9d7384f5-2a63-40f8-e2e0-0385eaefe40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19252\n",
            "6417\n",
            "0.2499902606256574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([\n",
        "    pd.Series(reasoning_conversations),\n",
        "    pd.Series(non_reasoning_subset)\n",
        "])\n",
        "data.name = \"text\"\n",
        "\n",
        "from datasets import Dataset\n",
        "combined_dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
        "combined_dataset = combined_dataset.shuffle(seed = 3407)"
      ],
      "metadata": {
        "id": "TCKfAKG_rbUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "HD9jQhIWrlpt",
        "outputId": "5b03501e-d4a2-4ccb-f852-cae2bc705f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        <|im_start|>user\\nGiven $\\sqrt{x^2+165}-\\sqrt{...\n",
              "1        <|im_start|>user\\nLet \\( \\sum a_n \\) be a conv...\n",
              "2        <|im_start|>user\\nFor \\( a > 0 \\), find the va...\n",
              "3        <|im_start|>user\\nCalculate $\\lim_{n\\to\\infty}...\n",
              "4        <|im_start|>user\\nFind all positive integers \\...\n",
              "                               ...                        \n",
              "59440    <|im_start|>user\\nConstruct a frequency polygo...\n",
              "35212    <|im_start|>user\\nWhat are the two primary typ...\n",
              "18726    <|im_start|>user\\nWhat measures can schools ta...\n",
              "14793    <|im_start|>user\\nWhy is a cavity with a hole ...\n",
              "68384    <|im_start|>user\\nWhat are some accurate and e...\n",
              "Name: text, Length: 25669, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nGiven $\\sqrt{x^2+165}-\\sqrt{...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nLet \\( \\sum a_n \\) be a conv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nFor \\( a &gt; 0 \\), find the va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nCalculate $\\lim_{n\\to\\infty}...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nFind all positive integers \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59440</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nConstruct a frequency polygo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35212</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nWhat are the two primary typ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18726</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nWhat measures can schools ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14793</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nWhy is a cavity with a hole ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68384</th>\n",
              "      <td>&lt;|im_start|&gt;user\\nWhat are some accurate and e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25669 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bfloat16_supported"
      ],
      "metadata": {
        "id": "qJ4lu1j_rmyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig"
      ],
      "metadata": {
        "id": "53nRckcPr5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_bfloat16_supported()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8iSoP9mr3Ap",
        "outputId": "2f4222f8-8ec2-4d0d-8670-0c9abd9a4dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=combined_dataset,\n",
        "    eval_dataset=None,\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field=\"text\",\n",
        "        per_device_train_batch_size=2,\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=30,\n",
        "        learning_rate=2e-4,\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2924a4b08a6b4b1f973e7a2a7b619da0",
            "b22756144c1b4f78959a3e98a42865d6",
            "19b2b0b38f4241caa8a6a39f2807c5ac",
            "588f89071f154c54a65d2cab0ec781d8",
            "9b9e6570047f42b8b1203d977e8f81f9",
            "858fa2e2fa5f444b9aa24ecacb2eda6b",
            "829d4ecccd014a4ea0dc75cd5ade9388",
            "cb72d7c91b6743f78397da55a197c005",
            "1c4b0e55869f485682efd901cf12b3c2",
            "6ad5f303286a48dd9a74877e66998aef",
            "4396a9bab5004f3585118ca908cb1e78"
          ]
        },
        "id": "37MbLtxZr4t4",
        "outputId": "92094aae-0e3c-40ec-b168-1cb0f1efc03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=12):   0%|          | 0/25669 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2924a4b08a6b4b1f973e7a2a7b619da0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axp1RI9mt1GN",
        "outputId": "09a6065e-c944-4679-9fb6-f28aeccd583f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = NVIDIA L4. Max memory = 22.161 GB.\n",
            "10.916 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x7-kHUnt5Nz",
        "outputId": "681b0887-a2e4-45fb-dfcd-824a946f672e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_CudaDeviceProperties(name='NVIDIA L4', major=8, minor=9, total_memory=22692MB, multi_processor_count=58, uuid=3c94905b-8c3b-459a-c3c2-325e7f9aff87, L2_cache_size=48MB)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "luDPNou8t_HA",
        "outputId": "6718651c-1bf8-434b-dbdf-8e98ccbc736c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 25,669 | Num Epochs = 1 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 128,450,560/14,000,000,000 (0.92% trained)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/30 13:13 < 02:12, 0.03 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.549900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.540300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.519000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.556100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.554200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.427100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.472800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.418000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.395600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.483900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.452600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.412400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.377400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.436000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.473300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.465800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.412000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.363800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.457500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 15:49, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.549900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.540300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.519000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.556100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.554200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.427100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.472800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.418000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.395600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.483900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.452600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.412400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.377400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.436000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.473300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.465800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.412000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.363800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.457500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.392000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.426500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.426800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.393500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.503800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAkAqNvYuGQH",
        "outputId": "10611385-9788-4c30-f81a-6a576bc3e3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "993.6763 seconds used for training.\n",
            "16.56 minutes used for training.\n",
            "Peak reserved memory = 14.773 GB.\n",
            "Peak reserved memory for training = 3.857 GB.\n",
            "Peak reserved memory % of max memory = 66.662 %.\n",
            "Peak reserved memory for training % of max memory = 17.404 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "ZnnK50fjx3tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"user\", \"content\" : \"Solve (x + 2)^2 = 0.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "JVGOEUFtxjh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)"
      ],
      "metadata": {
        "id": "-vOXt8OZx7Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wc1DW5JiyMzP",
        "outputId": "568f3741-500d-4446-bcd5-bf7c6112b25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>user\\nSolve (x + 2)^2 = 0.<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer"
      ],
      "metadata": {
        "id": "Nsbwdb3YyNtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.generate(**tokenizer(text, return_tensors=\"pt\").to(\"cuda\"), max_new_tokens = 256, temperature=0.7, top_p=0.8, top_k=20, streamer=TextStreamer(tokenizer, skip_prompt=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hLKBh5xyT8x",
        "outputId": "48f34726-8cfe-40b9-c8b1-0a86065f830e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve the equation (x + 2)^2 = 0, we can take the square root of both sides.\n",
            "\n",
            "sqrt((x + 2)^2) = sqrt(0)\n",
            "\n",
            "This simplifies to:\n",
            "\n",
            "|x + 2| = 0\n",
            "\n",
            "Since the absolute value of a number is always non-negative, the only way for |x + 2| to be 0 is if x + 2 = 0.\n",
            "\n",
            "Therefore, x = -2.\n",
            "\n",
            "So the solution to the equation (x + 2)^2 = 0 is x = -2.<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\" : \"user\", \"content\" : \"Solve (x + 2)^2 = 0.\"}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = False,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    enable_thinking = True, # Disable thinking\n",
        ")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
        "    max_new_tokens = 1024, # Increase for longer outputs!\n",
        "    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6HxP7PNypgX",
        "outputId": "4e995fca-9390-4560-8776-71b185161a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so I need to solve the equation (x + 2)^2 = 0. Hmm, let's see. I remember that when you have something squared equals zero, the solution is usually the value that makes the inside zero. Wait, because if you square a number and it equals zero, the only number that does that is zero itself. So, if (x + 2)^2 = 0, then x + 2 must be zero. Let me check that.\n",
            "\n",
            "So, starting with (x + 2)^2 = 0. If I take the square root of both sides, the left side becomes x + 2, and the right side becomes sqrt(0), which is 0. So, x + 2 = 0. Then, solving for x, I subtract 2 from both sides. That gives x = -2. \n",
            "\n",
            "Wait, but maybe I should verify this. Let me plug x = -2 back into the original equation to see if it works. Plugging in, we get (-2 + 2)^2 = (0)^2 = 0. Yeah, that's correct. So, x = -2 is the solution. \n",
            "\n",
            "Is there another solution? Well, since it's a quadratic equation, usually there are two solutions. But in this case, the equation is a perfect square, so both roots are the same. That means it's a repeated root. So, even though it's a quadratic, there's only one unique solution, which is x = -2. \n",
            "\n",
            "Let me think again. If I expand the equation, (x + 2)^2 = x^2 + 4x + 4. So, the equation becomes x^2 + 4x + 4 = 0. Then, using the quadratic formula: x = [-b ± sqrt(b^2 - 4ac)] / (2a). Here, a = 1, b = 4, c = 4. Plugging in, we get x = [-4 ± sqrt(16 - 16)] / 2. The discriminant is 16 - 16 = 0. So, sqrt(0) is 0. Therefore, x = [-4 ± 0] / 2 = -4/2 = -2. So, again, the solution is x = -2. \n",
            "\n",
            "Therefore, both methods confirm that the only solution is x = -2. Since the discriminant is zero, there's no other solution. So, the answer is x = -2. \n",
            "\n",
            "I guess that's all. The key here is recognizing that a squared term equals zero implies the term inside the square must be zero. Then, solving that gives the solution. Also, verifying by substitution and using the quadratic formula both lead to the same result, so I'm confident that's correct.\n",
            "</think>\n",
            "\n",
            "To solve the equation \\((x + 2)^2 = 0\\):\n",
            "\n",
            "1. Start with the given equation:\n",
            "   \\[\n",
            "   (x + 2)^2 = 0\n",
            "   \\]\n",
            "\n",
            "2. Take the square root of both sides:\n",
            "   \\[\n",
            "   \\sqrt{(x + 2)^2} = \\sqrt{0}\n",
            "   \\]\n",
            "   Simplifying both sides:\n",
            "   \\[\n",
            "   |x + 2| = 0\n",
            "   \\]\n",
            "\n",
            "3. Since the absolute value of a number is zero only if the number itself is zero, we have:\n",
            "   \\[\n",
            "   x + 2 = 0\n",
            "   \\]\n",
            "\n",
            "4. Solve for \\(x\\):\n",
            "   \\[\n",
            "   x = -2\n",
            "   \\]\n",
            "\n",
            "Verification:\n",
            "- Substitute \\(x = -2\\) back into the original equation:\n",
            "  \\[\n",
            "  (-2 + 2)^2 = 0^2 = 0\n",
            "  \\]\n",
            "  This confirms that \\(x = -2\\) is indeed a solution.\n",
            "\n",
            "Since the discriminant of the quadratic equation formed by expanding \\((x + 2)^2 = 0\\) is zero, the solution is a repeated root, but the only unique solution is:\n",
            "\\[\n",
            "\\boxed{-2}\n",
            "\\]<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E57LVX5Gy2wb",
        "outputId": "71d042fd-7b1c-4ceb-ca06-78b33dfb2e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/chat_template.jinja',\n",
              " 'lora_model/vocab.json',\n",
              " 'lora_model/merges.txt',\n",
              " 'lora_model/added_tokens.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = 2048,\n",
        "        load_in_4bit = True,\n",
        "    )"
      ],
      "metadata": {
        "id": "W-GkHzKJzQfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge to 16bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if True:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if True: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ],
      "metadata": {
        "id": "gn3KcZUIzZcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False:\n",
        "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ],
      "metadata": {
        "id": "i6kAaR7HzoC7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}